{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aula5.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pvujUqoNAbRc",
        "r857OWvYcBoX",
        "yHD7P3tvmOAN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0MYrUJ92EIL"
      },
      "source": [
        "# Imersão Dados - Alura\n",
        "\n",
        "## Aula 5 - Validação de modelo e _Overfit_\n",
        "\n",
        "Como foi visto na aula anterior, os modelos de _machine learning_ possuem uma dependência de fatores \"aleatórios\" que podem ser introduzidos desde as primeiras etapas do processo de criação de um modelo. Então vamos discutir formas de reduzir essa aleatoriedade e validar nosso modelo.\n",
        "\n",
        "### Índice\n",
        "\n",
        "- [Diminuindo efeitos de aleatoriedade: _Cross-validation_](#_cross-validation_)\n",
        "- [Embaralhando os dados](#embaralhando-os-dados)\n",
        "- [_Overfit_](#_overfit_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvujUqoNAbRc"
      },
      "source": [
        "### _Cross-validation_\n",
        "\n",
        "A primeira coisa a ser feita é utilizar um modelo que possua menos dependência do parâmetro `random_state` e o _decision tree_ atende esse requisito."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9zuiiL91_yE"
      },
      "source": [
        "# carrega os dados e separa\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dados = pd.read_csv('https://github.com/alura-cursos/imersao-dados-2-2020/blob/master/MICRODADOS_ENEM_2019_SAMPLE_43278.csv?raw=true')\n",
        "dados = dados[['NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_CN', 'NU_NOTA_REDACAO', 'NU_NOTA_MT']].dropna()\n",
        "x = dados[['NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_CN', 'NU_NOTA_REDACAO']]\n",
        "y = dados['NU_NOTA_MT']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "SEED = 1234\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.25, random_state=SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnlH1nn4B0kA",
        "outputId": "3c4c4825-5d5c-4842-d405-0494f6f23255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# roda modelo para conferir\n",
        "from sklearn.svm import LinearSVR\n",
        "modelo = LinearSVR(random_state=SEED)\n",
        "modelo.fit(x_treino, y_treino)\n",
        "predicao = novo_modelo.predict(x_teste)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(y_teste, predicao)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12745.739089201345"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDPPIEu_BPUX",
        "outputId": "3a28a6f9-1a92-4d37-b0e1-5948fe8a605d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# agora sim vai para o modelo arvore decisão\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "modelo_arvore = DecisionTreeRegressor(max_depth=3)\n",
        "modelo_arvore.fit(x_treino, y_treino)\n",
        "predicao_arvore = modelo_arvore.predict(x_teste)\n",
        "mean_squared_error(y_teste, predicao_arvore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5987.352568520455"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBkUs3SlD5it"
      },
      "source": [
        "Mas ainda temos fator de aleatoriedade que vem do processo de divisão dos dados e para mitigar esse efeito podemos utilizar o _cross-validation method_, que possui algumas variações mas vamos nos concentrar em apenas uma forma de aplicá-lo.\n",
        "\n",
        "Seguindo esse método, ao invés de separarmos nosso _DataSet_ em apenas dois grupos (treino e teste), vamos separá-lo em cinco grupos, por exemplo. Com os grupos separados vamos executar N rodadas de treino com os quatro primeiros e depois testar com o quinto. Após isso trocamos o grupo testado por um dos que utilizados no treinamento, e assim por diante até completar a rotação dos grupos. Dessa forma o resultado obtido será uma média de \"todos os modelos\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrFXcB8yK0ih",
        "outputId": "bc53b4ca-2e69-438a-b6c7-0d659a74c5d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "modelo_arvore = DecisionTreeRegressor(max_depth=3)\n",
        "cross_validate(modelo_arvore, x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.093436  , 0.08555746, 0.08088923, 0.07915139, 0.08505177]),\n",
              " 'score_time': array([0.00366378, 0.00273538, 0.00241041, 0.0025568 , 0.00253868]),\n",
              " 'test_score': array([0.48262421, 0.51140553, 0.48905884, 0.5252888 , 0.44483146])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5OVsSSEL0_o"
      },
      "source": [
        "O método `cross_validate` faz todas as etapas: a separação dos dados (cinco grupos por padrão) e as rodadas de treinamento e teste.\n",
        "\n",
        "E perceba que os valores de `test_score` parecem estar em uma escala diferente da que estavamos trabalhando, isso é porque a métrica padrão utlizada para avaliar o erro do modelo é uma grandeza diferente da que estávamos usando, então vamos especificar a grandeza que queremos e também a quantidade de grupos que os dados devem ser divididos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AkwwItfM4EN",
        "outputId": "2313c5ee-1e5a-45aa-933b-130a3334f814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "resultado_cv = cross_validate(modelo_arvore, x, y, scoring='neg_mean_squared_error', cv=10)\n",
        "resultado_cv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.10209703, 0.09092641, 0.08909249, 0.09380293, 0.08891463,\n",
              "        0.0875752 , 0.08738399, 0.08620048, 0.08725715, 0.08907795]),\n",
              " 'score_time': array([0.00176954, 0.00173926, 0.00162387, 0.00164247, 0.00166059,\n",
              "        0.0016222 , 0.00170636, 0.00179124, 0.00198793, 0.00165391]),\n",
              " 'test_score': array([-5686.95455159, -6035.40144634, -5830.55015277, -5958.32070827,\n",
              "        -5749.551073  , -6292.77890429, -6161.57457333, -6222.41251527,\n",
              "        -6141.63385177, -6603.98813674])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upx6kkaWNpvC"
      },
      "source": [
        "Agora note que os valores de erro estão mais parecidos com o que haviamos determinado, mas com sinal negativo. Isso ocorre devido a uma regra de desenvolvimento do `scikit-learn` de que \"quanto maior o valor melhor\". No caso do ERQ \"quanto mais próximo de zero melhor\", então tratando o erro como um valor negativo, a regra \"quanto maior melhor\" é satisfeita.\n",
        "\n",
        "Como não vamos utilizar outros processos de otimização que usam a mesma regra, podemos passar o ERQ para positivo e tirar a média de uma vez. Além disso podemos determinar o desvio padrão dos ERQs e determinar um intervalo de confiança:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UGstEeUQbe6",
        "outputId": "8a566c94-bf9b-48db-fa46-2f547ddf2c61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "media_cv = (resultado_cv['test_score']*-1).mean()\n",
        "media_cv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6068.3165913384655"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8m8-TcnRfep",
        "outputId": "ce933aed-8ad9-4edd-82aa-9f65771e67c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "desvio_cv = (resultado_cv['test_score']*-1).std()\n",
        "desvio_cv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "263.04166999750663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXARtKneZ9Ic",
        "outputId": "b61465c1-b111-4d9c-898b-7a72d39995bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "lim_inferior = media_cv - (2*desvio_cv)\n",
        "lim_superior = media_cv + (2*desvio_cv)\n",
        "print(f\"Intervalo de confiança: {lim_inferior} - {lim_superior}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intervalo de confiança: 5542.233251343452 - 6594.399931333479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3--jR5oa9_-"
      },
      "source": [
        "# função para calculo do intervalo de confiança\n",
        "def calcula_erro(resultados_df):\n",
        "    media = (resultados_df['test_score']*-1).mean()\n",
        "    desvio = (resultados_df['test_score']*-1).std()\n",
        "    lim_inferior = media - (2*desvio)\n",
        "    lim_superior = media + (2*desvio)\n",
        "    print(f\"Intervalo de confiança: {lim_inferior} - {lim_superior}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r857OWvYcBoX"
      },
      "source": [
        "### Embaralhando os dados\n",
        "\n",
        "Se verificarmos a documentação do método [`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) vamos perceber que ele não tem um parâmetro de aleatoriedade e a forma como a divisão dos dados é feita é bem definida. Isso significa que se o _DataSet_ estiver organizado em ordem crescente de acordo com alguma das notas, por exemplo, podemos ter um modelo com resultados enviesados.\n",
        "\n",
        "Podemos embaralhar os dados usando um método da biblioteca `scikit-learn`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9mRTnlkdfB5",
        "outputId": "6b0948ef-33c5-4680-d450-6fd4fc6a2d3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "partes = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "calcula_erro(cross_validate(modelo_arvore, x, y, scoring='neg_mean_squared_error', cv=partes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intervalo de confiança: 5824.493018231576 - 6298.992449847258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCWHqJ9jfcGT"
      },
      "source": [
        "E também podemos definir um _random state_, basta executar um método da biblioteca `numpy` na célula e as operações passam a ser executadas com esse fator de aleatoriedade (?)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPg-02RYf4Bg",
        "outputId": "84d56a0c-8e7b-43c4-d525-232742c4104a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# sem fator aleatorio definido\n",
        "calcula_erro(cross_validate(modelo_arvore, x, y, scoring='neg_mean_squared_error', cv=partes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intervalo de confiança: 5820.353373452573 - 6297.575473759863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cse02mSvgBsa",
        "outputId": "9f008367-833b-4f02-cdcb-2d40c785b786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# definindo fator aleatorio\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(SEED)\n",
        "\n",
        "calcula_erro(cross_validate(modelo_arvore, x, y, scoring='neg_mean_squared_error', cv=partes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intervalo de confiança: 5910.513672291329 - 6210.679992504457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn7FpJZdga1P",
        "outputId": "91974475-bba5-49a1-f8e5-6c3e34724057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# executando novamente com o mesmo fator de aleatoriedade\n",
        "np.random.seed(SEED)\n",
        "calcula_erro(cross_validate(modelo_arvore, x, y, scoring='neg_mean_squared_error', cv=partes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intervalo de confiança: 5910.513672291329 - 6210.679992504457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHD7P3tvmOAN"
      },
      "source": [
        "### _Overfit_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1p4Y104k3pg"
      },
      "source": [
        "def regressor_arvore(nivel_mais_profundo):\n",
        "    valor_maximo = 20\n",
        "    nivel_mais_profundo = valor_maximo if (nivel_mais_profundo < 1 or nivel_mais_profundo > valor_maximo) else nivel_mais_profundo\n",
        "\n",
        "    print(\"Nível\\tMédia (ERQ)\\t\\tDesvio padrão\")\n",
        "    for nivel in range(1, nivel_mais_profundo+1):\n",
        "        np.random.seed(SEED)\n",
        "        partes = KFold(n_splits=10, shuffle=True)\n",
        "        modelo_arvore = DecisionTreeRegressor(max_depth=nivel)\n",
        "        resultados = cross_validate(modelo_arvore, x, y, scoring='neg_mean_squared_error', cv=partes)\n",
        "\n",
        "        media = (resultados['test_score']*-1).mean()\n",
        "        desvio = (resultados['test_score']*-1).std()\n",
        "        lim_inferior = media - (2*desvio)\n",
        "        lim_superior = media + (2*desvio)\n",
        "        \n",
        "        # print(f\"{nivel}\\t{media}\\t{lim_superior - lim_inferior}\")\n",
        "        print(f\"{nivel}\\t{media}\\t{desvio}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BydVP4bEmOyz",
        "outputId": "69437de2-9057-4732-8fe6-d124175d852a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "regressor_arvore(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nível\t|Média (ERQ)\t\t|Desvio padrão\n",
            "1\t7866.927011683838\t65.33626494272087\n",
            "2\t6558.321643161868\t75.92664374939238\n",
            "3\t6060.596832397893\t75.0415800532818\n",
            "4\t5831.914600536327\t73.63692970409825\n",
            "5\t5691.016497534935\t79.58409872098808\n",
            "6\t5591.73672389537\t71.7875095008164\n",
            "7\t5536.431104799163\t62.21478643073848\n",
            "8\t5542.102109416983\t72.89547409382575\n",
            "9\t5591.8419392935775\t71.29206246665687\n",
            "10\t5731.32564405446\t65.79248497846966\n",
            "11\t5915.804789201808\t80.93533670789705\n",
            "12\t6179.0090814897785\t81.7524210056854\n",
            "13\t6505.0166634314355\t111.04682238290856\n",
            "14\t6828.826593401468\t113.15901341339163\n",
            "15\t7199.633672703089\t92.8101440766405\n",
            "16\t7573.52893043737\t113.64179827624405\n",
            "17\t7959.784852838859\t134.0793247637921\n",
            "18\t8357.188510330792\t131.9068585877019\n",
            "19\t8767.980901546043\t130.12327404153444\n",
            "20\t9122.313721122862\t123.63080258328979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Yvf7n_0s424"
      },
      "source": [
        "Podemos notar que conforme o nível vai aumentando o ERQ vai diminuindo, porém esse comportamento ocorre até um certo nível. Neste caso a partir do nível 8 o ERQ passa a aumentar.\n",
        "\n",
        "Vamos passar o parâmetro `return_train_score` como `True` ao chamar o método `cross_validate` para que o _score_ dos dados de treino também sejam retornados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngQjKHV5mXmb"
      },
      "source": [
        "def regressor_arvore(nivel_mais_profundo):\n",
        "    valor_maximo = 20\n",
        "    nivel_mais_profundo = valor_maximo if (nivel_mais_profundo < 1 or nivel_mais_profundo > valor_maximo) else nivel_mais_profundo\n",
        "\n",
        "    print(\"Profundidade\\t| Média (treino)\\t| Desvio padrão\\t\\t| Média (teste)\\t\\t| Desvio padrão\\t\")\n",
        "    print(\"----------------|-----------------------|-----------------------|-----------------------|------------------\")\n",
        "    for nivel in range(1, nivel_mais_profundo+1):\n",
        "        np.random.seed(SEED)\n",
        "        partes = KFold(n_splits=10, shuffle=True)\n",
        "        modelo_arvore = DecisionTreeRegressor(max_depth=nivel)\n",
        "\n",
        "        resultados = cross_validate(modelo_arvore, x, y, scoring='neg_mean_squared_error', cv=partes, return_train_score=True)\n",
        "\n",
        "        media_treino = (resultados['train_score']*-1).mean()\n",
        "        desvio_treino = (resultados['train_score']*-1).std()\n",
        "        media_teste = (resultados['test_score']*-1).mean()\n",
        "        desvio_teste = (resultados['test_score']*-1).std()\n",
        "        \n",
        "        print(f\"{nivel}\\t\\t|{media_treino}\\t|{desvio_treino}\\t|{media_teste}\\t|{desvio_teste}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ueAtyYcqDYo",
        "outputId": "239c324f-89e4-40a7-ee32-254a27772681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "regressor_arvore(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Profundidade\t| Média (treino)\t| Desvio padrão\t\t| Média (teste)\t\t| Desvio padrão\t\n",
            "----------------|-----------------------|-----------------------|-----------------------|------------------\n",
            "1\t\t|7849.445766058474\t|7.545010440052587\t|7866.927011683838\t|65.33626494272087\n",
            "2\t\t|6532.7483836249085\t|8.237688160023687\t|6558.321643161868\t|75.92664374939238\n",
            "3\t\t|6025.718727804219\t|8.25577596657425\t|6060.596832397893\t|75.0415800532818\n",
            "4\t\t|5766.615419484886\t|9.343600244926202\t|5831.914600536327\t|73.63692970409825\n",
            "5\t\t|5604.129644787683\t|10.004259579957926\t|5691.016497534935\t|79.58409872098808\n",
            "6\t\t|5470.794376514847\t|9.862625980188787\t|5591.73672389537\t|71.7875095008164\n",
            "7\t\t|5368.22113220513\t|8.42960342995329\t|5536.431104799163\t|62.21478643073848\n",
            "8\t\t|5275.114664891669\t|9.782089735034074\t|5542.102109416983\t|72.89547409382575\n",
            "9\t\t|5166.478005291161\t|11.07054312283756\t|5591.8419392935775\t|71.29206246665687\n",
            "10\t\t|5023.719373671476\t|12.278287771867753\t|5731.32564405446\t|65.79248497846966\n",
            "11\t\t|4835.375975792986\t|13.89394818316394\t|5915.804789201808\t|80.93533670789705\n",
            "12\t\t|4599.869858349329\t|15.904474891889173\t|6179.0090814897785\t|81.7524210056854\n",
            "13\t\t|4322.033922382094\t|15.039379530653651\t|6505.0166634314355\t|111.04682238290856\n",
            "14\t\t|4006.6178391200483\t|15.24600171116353\t|6828.826593401468\t|113.15901341339163\n",
            "15\t\t|3665.5287576839255\t|22.534211661783015\t|7199.633672703089\t|92.8101440766405\n",
            "16\t\t|3311.410855707875\t|31.80770644571603\t|7573.52893043737\t|113.64179827624405\n",
            "17\t\t|2951.9110064941656\t|43.351536242837625\t|7959.784852838859\t|134.0793247637921\n",
            "18\t\t|2598.6711386531306\t|52.981069122172386\t|8357.188510330792\t|131.9068585877019\n",
            "19\t\t|2260.163764962523\t|60.290515156099396\t|8767.980901546043\t|130.12327404153444\n",
            "20\t\t|1942.2926354595725\t|64.98805245233439\t|9122.313721122862\t|123.63080258328979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw1CGEwKwPRF"
      },
      "source": [
        "Ao contrário do que foi observado para os para os dados de teste, para os dados de treino verificamos que não há um \"ponto de retorno\". Para estes, a medida que a profundidade aumenta temos um ERQ cada vez menor.\n",
        "\n",
        "O que acontece é que o modelo está ficando muito bom com os dados de treino,como se estivesse praticamente decorando eles, esse comportamento é chamado de _overfit_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK9hyD7wuOnd"
      },
      "source": [
        "# pesquisar sobre intervalo de confiança\n",
        "# testar outros parâmetros do DecisionTreeRegressor()\n",
        "# procurar outras formas de realizar os ajustes de parâmetros com o sklearn\n",
        "# pesquisar o que é o problema de underfit\n",
        "# plotar gráficos de 'test_score x train_score' e '*_score x `parâmetro do modelo`'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}